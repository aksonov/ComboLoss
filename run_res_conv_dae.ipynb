{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f8f866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from scipy import spatial\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torchvision import transforms\n",
    "\n",
    "sys.path.append('../')\n",
    "from models import ssim\n",
    "from models.resconvdae import *\n",
    "from models.losses import ReconstructionLoss\n",
    "from data.data_loaders import load_reconstruct_scutfbp, load_reconstruct_hotornot, load_reconstruct_scutfbp5500_64, \\\n",
    "    load_reconstruct_scutfbp5500_cv\n",
    "from util.file_util import mkdirs_if_not_exist\n",
    "from config.cfg import cfg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "791bcdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs, inference=False):\n",
    "    \"\"\"\n",
    "    train model\n",
    "    :param model:\n",
    "    :param dataloaders:\n",
    "    :param criterion:\n",
    "    :param optimizer:\n",
    "    :param scheduler:\n",
    "    :param num_epochs:\n",
    "    :param inference:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    print(model)\n",
    "    model_name = model.__class__.__name__\n",
    "    model = model.float()\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() and cfg['use_gpu'] else 'cpu')\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device)\n",
    "\n",
    "    dataset_sizes = {x: len(dataloaders[x].dataset) for x in ['train', 'val', 'test']}\n",
    "\n",
    "    for k, v in dataset_sizes.items():\n",
    "        print('Dataset size of {0} is {1}...'.format(k, v))\n",
    "\n",
    "    if not inference:\n",
    "        print('Start training %s...' % model_name)\n",
    "        since = time.time()\n",
    "\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "        best_ssim = 0.0\n",
    "        best_cosine_similarity = 0.0\n",
    "        best_l2_dis = float('inf')\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print('-' * 100)\n",
    "            print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "\n",
    "            # Each epoch has a training and validation phase\n",
    "            for phase in ['train', 'val']:\n",
    "                if phase == 'train':\n",
    "                    if torch.__version__ <= '1.1.0':\n",
    "                        scheduler.step()\n",
    "                    model.train()  # Set model to training mode\n",
    "                else:\n",
    "                    model.eval()  # Set model to evaluate mode\n",
    "\n",
    "                running_loss = 0.0\n",
    "                running_ssim = 0.0\n",
    "                running_l2_dis = 0.0\n",
    "                running_cos_sim = 0.0\n",
    "\n",
    "                # Iterate over data.\n",
    "                # for data in dataloaders[phase]:\n",
    "                for i, data in enumerate(dataloaders[phase], 0):\n",
    "\n",
    "                    inputs = data['image']\n",
    "                    inputs = inputs.to(device)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(inputs)\n",
    "\n",
    "                        loss = criterion(outputs, inputs)\n",
    "\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.sum().backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.sum() * inputs.size(0)\n",
    "                    running_cos_sim += 1 - spatial.distance.cosine(outputs.to('cpu').detach().numpy().ravel(),\n",
    "                                                                   inputs.to('cpu').detach().numpy().ravel())\n",
    "                    running_l2_dis += np.linalg.norm(\n",
    "                        outputs.to('cpu').detach().numpy().ravel() - inputs.to('cpu').detach().numpy().ravel())\n",
    "                    running_ssim += ssim.ssim(outputs, inputs)\n",
    "\n",
    "                if phase == 'train':\n",
    "                    if torch.__version__ >= '1.1.0':\n",
    "                        scheduler.step()\n",
    "\n",
    "                epoch_loss = running_loss / dataset_sizes[phase]\n",
    "                epoch_l2_dis = running_l2_dis / dataset_sizes[phase]\n",
    "                epoch_cos_sim = running_cos_sim / dataset_sizes[phase]\n",
    "                epoch_ssim = running_ssim / dataset_sizes[phase]\n",
    "\n",
    "                print('{} Loss: {:.4f} L2_Distance: {} Cosine_Similarity: {} SSIM: {}'\n",
    "                      .format(phase, epoch_loss, epoch_l2_dis, epoch_cos_sim, epoch_ssim))\n",
    "\n",
    "                # deep copy the model\n",
    "                if phase == 'val' and epoch_l2_dis <= best_l2_dis:\n",
    "                    best_l2_dis = epoch_l2_dis\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "                    model.load_state_dict(best_model_wts)\n",
    "                    model_path_dir = './model'\n",
    "                    mkdirs_if_not_exist(model_path_dir)\n",
    "                    state_dict = model.module.state_dict() if torch.cuda.device_count() > 1 else model.state_dict()\n",
    "                    torch.save(state_dict, './model/{0}_best_epoch-{1}.pth'.format(model_name, epoch))\n",
    "\n",
    "        time_elapsed = time.time() - since\n",
    "        print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "        print('Best L2_Distance: {:4f}'.format(best_l2_dis))\n",
    "\n",
    "        # load best model weights\n",
    "        model.load_state_dict(best_model_wts)\n",
    "        model_path_dir = './model'\n",
    "        mkdirs_if_not_exist(model_path_dir)\n",
    "        state_dict = model.module.state_dict() if torch.cuda.device_count() > 1 else model.state_dict()\n",
    "        torch.save(state_dict, './model/%s.pth' % model_name)\n",
    "    else:\n",
    "        print('Start testing %s...' % model.__class__.__name__)\n",
    "        model.load_state_dict(torch.load(os.path.join('./model/%s.pth' % model_name)))\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    cos_sim, l2_dist, ssim_ = 0.0, 0.0, 0.0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in dataloaders['test']:\n",
    "            images = data['image']\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)\n",
    "\n",
    "            cos_sim += 1 - spatial.distance.cosine(outputs.to('cpu').detach().numpy().ravel(),\n",
    "                                                   images.to('cpu').detach().numpy().ravel())\n",
    "            l2_dist += np.linalg.norm(\n",
    "                outputs.to('cpu').detach().numpy().ravel() - images.to('cpu').detach().numpy().ravel())\n",
    "            ssim_ += ssim.ssim(outputs, images)\n",
    "\n",
    "    print('*' * 200)\n",
    "    print('Avg L2 Distance of {0} on test set: {1}'.format(model_name, l2_dist / dataset_sizes['test']))\n",
    "    print('Avg CosineSimilarity of {0} on test set: {1}'.format(model_name, cos_sim / dataset_sizes['test']))\n",
    "    print('Avg SSIM of {0} on test set: {1}'.format(model_name, ssim_ / dataset_sizes['test']))\n",
    "    print('*' * 200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20d83cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(model, data_name):\n",
    "    \"\"\"\n",
    "    train model\n",
    "    :param model:\n",
    "    :param data_name: SCUT-FBP/HotOrNot/SCUT-FBP5500/SCUT-FBP5500CV\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # criterion = ReconstructionLoss()\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    optimizer_ft = optim.Adam(model.parameters(), lr=0.01, weight_decay=1e-4)\n",
    "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer_ft, step_size=100, gamma=0.1)\n",
    "\n",
    "    if data_name == 'SCUT-FBP':\n",
    "        print('start loading SCUTFBPDataset...')\n",
    "        dataloaders = load_reconstruct_scutfbp()\n",
    "    elif data_name == 'HotOrNot':\n",
    "        print('start loading HotOrNotDataset...')\n",
    "        dataloaders = load_reconstruct_hotornot(cv_split_index=cfg['cv_index'])\n",
    "    elif data_name == 'SCUT-FBP5500':\n",
    "        print('start loading SCUTFBP5500Dataset...')\n",
    "        dataloaders = load_reconstruct_scutfbp5500_64()\n",
    "    elif data_name == 'SCUT-FBP5500CV':\n",
    "        print('start loading SCUTFBP5500Dataset Cross Validation...')\n",
    "        dataloaders = load_reconstruct_scutfbp5500_cv(cfg['cv_index'])\n",
    "    else:\n",
    "        print('Invalid data name. It can only be SCUT-FBP or HotOrNot...')\n",
    "        sys.exit(0)\n",
    "\n",
    "    train_model(model=model, dataloaders=dataloaders, criterion=criterion, optimizer=optimizer_ft,\n",
    "                scheduler=exp_lr_scheduler, num_epochs=cfg['epoch'], inference=False)\n",
    "\n",
    "\n",
    "def ext_res_dae_feat(img, res_dae):\n",
    "    \"\"\"\n",
    "    extract deep features from Residual Deep AutoEncoder's encoder module\n",
    "    :param img:\n",
    "    :param res_dae:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    if isinstance(img, str):\n",
    "        img = Image.open(img)\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    img = preprocess(img)\n",
    "    img.unsqueeze_(0)\n",
    "    img = img.to(device)\n",
    "    encoder = res_dae.module.encoder if torch.cuda.device_count() > 1 else res_dae.encoder\n",
    "    feat = encoder(img).to(\"cpu\").detach().numpy().ravel()\n",
    "\n",
    "    return feat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6a07f607",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_img_with_dae(img_f, model):\n",
    "    \"\"\"\n",
    "    generate reconstructed image with ResConvDAE\n",
    "    :param img_f:\n",
    "    :param model:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    img = io.imread(img_f)\n",
    "    img = Image.fromarray(img.astype(np.uint8))\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    img = preprocess(img)\n",
    "    img.unsqueeze_(0)\n",
    "    img = img.to(device)\n",
    "    output = model(img)\n",
    "\n",
    "    output = output.to(\"cpu\").detach().numpy().astype(np.float)[0].transpose([1, 2, 0])\n",
    "    output[:, :, 0] *= 0.229\n",
    "    output[:, :, 0] += 0.485\n",
    "    output[:, :, 1] *= 0.224\n",
    "    output[:, :, 1] += 0.456\n",
    "    output[:, :, 2] *= 0.225\n",
    "    output[:, :, 2] += 0.406\n",
    "    output *= 255.0\n",
    "    output = output.clip(0, 255)\n",
    "    output = Image.fromarray(np.uint8(output), mode='RGB')\n",
    "\n",
    "    os.makedirs(args['save_to_dir'], exist_ok=True)\n",
    "    output.save('./{}/gen_{}'.format(args['save_to_dir'], img_f.split(os.path.sep)[-1]))\n",
    "    print(f'Reconstructed image for {os.path.basename(img_f)} has been generated...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "169a1e1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolab\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m drive\n\u001b[1;32m      2\u001b[0m drive\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1de99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_conv_dae = ResConvDAE()\n",
    "main(res_conv_dae, 'SCUT-FBP5500')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
